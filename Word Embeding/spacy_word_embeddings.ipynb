{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "996c3bb1-4d3e-449a-80bb-9b07fb648bde",
   "metadata": {},
   "source": [
    "# spacy_text_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13600a2-b3a5-4318-9917-c634546c3d6f",
   "metadata": {},
   "source": [
    "We will classify whether a given text belongs to one of the possible classes ['BUSINESS', 'SPORTS', 'CRIME'].\n",
    "\n",
    "We will use spacy to pre-process the text, convert text to numbers, and apply different classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d3b4c8-b9ec-4c4d-8412-11cbde4d824d",
   "metadata": {},
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae9e5840-4a3c-45b8-80ac-ff441edbace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy and load the language model downloaded\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ae449-a616-4290-b707-63bf067c0a8a",
   "metadata": {},
   "source": [
    "# News Category Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26786696-fa44-4b5c-97c3-7da25d896320",
   "metadata": {},
   "source": [
    "\n",
    "Credits: https://www.kaggle.com/code/hengzheng/news-category-classifier-val-acc-0-65\n",
    "\n",
    "This data consists of two columns. - Text - Category\n",
    "\n",
    "Text are the description about a particular topic.\n",
    "    \n",
    "Category determine which class the text belongs to.\n",
    "    \n",
    "we have classes mainly of 'BUSINESS', 'SPORTS', 'CRIME' and comes under Multi-class classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "989969b1-044b-4adc-97c3-df20dcfeea39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'Fake_Real_Data.csv', 'news_dataset.json', 'spacy_word_embeddings.ipynb', 'word_vectors_spacy_text_classification.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())  # Check if the file is in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cbba556-4430-4294-b9a1-cf6c44499dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'0': 'Larry Nassar Blames His Victims, Says H...</td>\n",
       "      <td>{'0': 'CRIME', '1': 'CRIME', '2': 'SPORTS', '3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  {'0': 'Larry Nassar Blames His Victims, Says H...   \n",
       "\n",
       "                                            category  \n",
       "0  {'0': 'CRIME', '1': 'CRIME', '2': 'SPORTS', '3...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#read the dataset \"news_dataset.json\" provided and load it into dataframe \"df\"\n",
    "df = pd.read_json('news_dataset.json', lines=True)\n",
    "\n",
    "\n",
    "#print the shape of data\n",
    "print(df.shape)\n",
    "\n",
    "#print the top5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365caab-59f6-47ed-bb0f-7aa7d7f364d8",
   "metadata": {},
   "source": [
    "# Preprocess the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c32f57c8-081d-43fd-8bba-c348a0906988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this utility function to preprocess the text\n",
    "#1. Remove the stop words\n",
    "#2. Convert to base form using lemmatisation\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332840db-3500-42f4-b924-37a1d1e2b76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (7500, 2)\n",
      "Dataset columns: Index(['text', 'category'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load JSON file into DataFrame\n",
    "df = pd.read_json('news_dataset.json')\n",
    "\n",
    "# Check the dataset shape and columns\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Dataset columns:\", df.columns)\n",
    "\n",
    "# Ensure the column 'text' exists\n",
    "if 'text' not in df.columns:\n",
    "    raise ValueError(\"The column 'text' is missing in the dataset.\")\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Apply preprocessing to the text column\n",
    "df['preprocessed_text'] = df['text'].apply(lambda text: preprocess(text))\n",
    "\n",
    "# Display the preprocessed data\n",
    "print(df[['text', 'preprocessed_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547991ad-b845-4a4a-9d81-1e2f9a909e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    print(f\"Processing text: {text}\")\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return ' '.join(filtered_tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
