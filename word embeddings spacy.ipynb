{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e205f758-4caa-44c4-ad8d-967d7c35e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# word vectors occupy lot of space. hence en_core_web_sm model do not have them included. \n",
    "# In order to download\n",
    "# word vectors you need to install large or medium english model. We will install the large one!\n",
    "# make sure you have run \"python -m spacy download en_core_web_lg\" to install large english model\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dcea7fa-b2c3-45b7-bfcd-992129002e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog Vector: True OOV: True\n",
      "cat Vector: True OOV: True\n",
      "banana Vector: True OOV: True\n",
      "kem Vector: True OOV: True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"dog cat banana kem\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, \"Vector:\", token.has_vector, \"OOV:\", token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba4b76ce-36b6-4785-b024-b00f702e9730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6c98ca5-9ca2-4585-894b-f2623fe0e83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_token = nlp(\"bread\")\n",
    "base_token.vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0365ba70-5d2d-4028-80d2-ab53b9ada660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bread <-> bread: 0.5200659036636353\n",
      "sandwich <-> bread: 0.26070114970207214\n",
      "burger <-> bread: 0.13107281923294067\n",
      "car <-> bread: 0.16306430101394653\n",
      "tiger <-> bread: 0.3073519170284271\n",
      "human <-> bread: 0.062681645154953\n",
      "wheat <-> bread: 0.40764638781547546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5372\\2510959949.py:4: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(f\"{token.text} <-> {base_token.text}:\", token.similarity(base_token))\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"bread sandwich burger car tiger human wheat\")\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text} <-> {base_token.text}:\", token.similarity(base_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f7979d-7056-494a-a541-0e573fbb1167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_similarity(base_word, words_to_compare):\n",
    "    base_token = nlp(base_word)\n",
    "    doc = nlp(words_to_compare)\n",
    "    for token in doc:\n",
    "        print(f\"{token.text} <-> {base_token.text}: \", token.similarity(base_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8184f3c1-c367-4683-a61c-d41dbca60c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple <-> iphone:  0.5248112678527832\n",
      "samsung <-> iphone:  0.24435679614543915\n",
      "iphone <-> iphone:  0.43426281213760376\n",
      "dog <-> iphone:  0.3711053133010864\n",
      "kitten <-> iphone:  0.35084104537963867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5372\\1721280760.py:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(f\"{token.text} <-> {base_token.text}: \", token.similarity(base_token))\n"
     ]
    }
   ],
   "source": [
    "print_similarity(\"iphone\", \"apple samsung iphone dog kitten\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c84b9147-0c76-49e7-8ed3-66d2224bf296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78808445]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "king = nlp.vocab[\"king\"].vector\n",
    "man = nlp.vocab[\"man\"].vector\n",
    "woman = nlp.vocab[\"woman\"].vector\n",
    "queen = nlp.vocab[\"queen\"].vector\n",
    "\n",
    "result = king - man + woman\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity([result], [queen])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
